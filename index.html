<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <!-- Meta tags for social media banners -->
  <meta name="description" content="DESCRIPTION META TAG">
  <meta property="og:title" content="SOCIAL MEDIA TITLE TAG"/>
  <meta property="og:description" content="SOCIAL MEDIA DESCRIPTION TAG TAG"/>
  <meta property="og:url" content="URL OF THE WEBSITE"/>
  <meta property="og:image" content="static/image/your_banner_image.png" />
  <meta property="og:image:width" content="1200"/>
  <meta property="og:image:height" content="630"/>

  <meta name="twitter:title" content="TWITTER BANNER TITLE META TAG">
  <meta name="twitter:description" content="TWITTER BANNER DESCRIPTION META TAG">
  <meta name="twitter:image" content="static/images/your_twitter_banner_image.png">
  <meta name="twitter:card" content="summary_large_image">

  <meta name="keywords" content="KEYWORDS SHOULD BE PLACED HERE">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <title>Self-Prompting Diffusion Transformer for Open-Vocabulary Scene Text Editing via In-Context Learning</title>

  <!-- Fonts -->
  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro" rel="stylesheet">

  <!-- Stylesheets -->
  <link rel="stylesheet" href="static/css/bulma.min.css">
  <link rel="stylesheet" href="static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="static/css/index.css">

  <!-- 底部图片网格样式 -->
  <style>
    .results-section {
      padding: 4rem 1.5rem;
      background-color: #f5f5f5;
    }
    .results-container {
      max-width: 1200px;
      margin: 0 auto;
    }
    .results-grid {
      display: grid;
      grid-template-columns: repeat(auto-fit, minmax(400px, 1fr));
      gap: 2.5rem;
      margin-top: 2rem;
    }
    .result-item {
      display: flex;
      flex-direction: column;
      align-items: center;
      background: #fff;
      padding: 1rem;
      border-radius: 8px;
      box-shadow: 0 4px 6px rgba(0,0,0,0.05);
      transition: transform 0.2s ease, box-shadow 0.2s ease;
    }
    .result-item:hover {
      transform: translateY(-5px);
      box-shadow: 0 8px 15px rgba(0,0,0,0.1);
    }
    .result-item img {
      width: 100%;
      height: auto;
      object-fit: contain;
      border-radius: 4px;
      border: 1px solid #eee;
    }
    .result-caption {
      margin-top: 1rem;
      font-size: 1rem;
      color: #555;
      text-align: center;
      font-weight: 500;
    }
    
    /* 响应式调整 */
    @media (max-width: 768px) {
      .results-grid {
        grid-template-columns: 1fr;
        gap: 2rem;
      }
    }
  </style>

  <!-- Scripts -->
  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
  <script defer src="static/js/fontawesome.all.min.js"></script>
  <script src="static/js/bulma-slider.min.js"></script>
  <script src="static/js/index.js"></script>
</head>

<body>

<!-- ===================== HERO ===================== -->
<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">
            Self-Prompting Diffusion Transformer for Open-Vocabulary Scene Text Editing via In-Context Learning
          </h1>
          <div class="is-size-5 publication-authors has-text-centered">
            <span class="author-block">Anonymous Authors</span>
          </div>
          <!-- Paper button (non-clickable) -->
          <div class="column has-text-centered">
            <div class="publication-links">
              <span class="link-block">
                <span class="button is-normal is-rounded is-dark is-static">
                  <span class="icon"><i class="fas fa-file-pdf"></i></span>
                  <span>Paper</span>
                </span>
              </span>
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<!-- ===================== TEASER ===================== -->
<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body has-text-centered">
      <img src="static/images/qualitative.png"
           alt="Qualitative Scene Text Editing Results"
           style="max-width: 100%; height: auto;">
      <h2 class="subtitle has-text-centered">
        Qualitative results of open-vocabulary and style-consistent scene text editing.
      </h2>
    </div>
  </div>
</section>

<!-- ===================== ABSTRACT ===================== -->
<section class="section hero is-light">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            Scene text editing aims to modify text within a target region of an image while preserving the surrounding background appearance, including style and texture.
            Existing methods primarily rely on background image information while neglecting the visual details of the target text regions, which leads to the loss of stylistic characteristics inherent in the original text and effectively degrades the task to generic text rendering.
            Moreover, the constraints imposed by pre-trained glyph encoders further limit the diversity and vocabulary of editable text.
            To address these limitations, we propose a self-prompting scene text editing framework that directly constructs both style and glyph prompts from the original image itself, without introducing additional style or glyph encoders.
            Our approach adopts a two-stage training strategy, where the diffusion transformer is first trained on large-scale self-supervised data and subsequently refined using a small set of paired images.
            By leveraging the in-context learning capability of a Multi-Modal Diffusion Transformer (MM-DiT), the proposed method enables open-vocabulary and style-consistent scene text editing.
            Extensive experiments across multiple languages demonstrate that our method achieves state-of-the-art performance in terms of both text accuracy and style consistency.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>

<!-- ===================== METHOD ===================== -->
<section class="section hero is-light">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Method</h2>
        <div class="content has-text-justified">
          <p>
            Our method is built upon <em>FLUX-Fill</em>, an inpainting-oriented variant of MMDiT, which formulates image editing as a conditional rectified flow process in the latent space and employs a transformer-based architecture to jointly reason over visual content, spatial structure, and textual semantics under multimodal conditions.
          </p>
        </div>
        <div style="margin-top: 2.5rem; overflow: visible;">
          <img src="static/images/framework.png"
               alt="Method Framework"
               style="display: block; max-width: 120%; height: auto; position: relative; left: 50%; transform: translateX(-50%);">
        </div>
      </div>
    </div>
  </div>
</section>

<!-- ===================== COMPARISONS ===================== -->
<section class="section hero is-light">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Quantitative Results</h2>
        <div class="has-text-centered" style="margin-top: 2rem;">
          <img src="static/images/table.jpg" alt="Comparisons with SOTA Methods" style="max-width: 100%; height: auto;">
        </div>
      </div>
    </div>
  </div>
</section>

<!-- ===================== MORE QUALITATIVE RESULTS (MOVED TO BOTTOM) ===================== -->
<section class="results-section">
  <div class="results-container">
    <h2 class="title is-3 has-text-centered">More Qualitative Results</h2>
    <div class="results-grid">
      
      <!-- Item 1 -->
      <div class="result-item">
        <img src="static/images/ja.png" alt="Japanese result">
      </div>

      <!-- Item 2 -->
      <div class="result-item">
        <img src="static/images/ko.png" alt="Korean result">
      </div>

      <!-- Item 3 -->
      <div class="result-item">
        <img src="static/images/ru.png" alt="Russian result">
      </div>

      <!-- Item 4 -->
      <div class="result-item">
        <img src="static/images/zh.png" alt="Chinese result">
      </div>

      <!-- Item 5 -->
      <div class="result-item">
        <img src="static/images/en.png" alt="English result">
      </div>

    </div>
  </div>
</section>

<footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>
            This page was built using the
            <a href="https://github.com/eliahuhorwitz/Academic-project-page-template" target="_blank">
              Academic Project Page Template
            </a>.
          </p>
        </div>
      </div>
    </div>
  </div>
</footer>

</body>
</html>
